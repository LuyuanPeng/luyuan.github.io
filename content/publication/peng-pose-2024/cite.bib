@misc{peng_pose_2024,
 abstract = {High-precision localization is pivotal in underwater reinspection missions. Traditional localization methods like inertial navigation systems, Doppler velocity loggers, and acoustic positioning face significant challenges and are not cost-effective for some applications. Visual localization is a cost-effective alternative in such cases, leveraging the cameras already equipped on inspection vehicles to estimate poses from images of the surrounding scene. Amongst these, machine learning-based pose estimation from images shows promise in underwater environments, performing efficient relocalization using models trained based on previously mapped scenes. We explore the efficacy of learning-based pose estimators in both clear and turbid water inspection missions, assessing the impact of image formats, model architectures and training data diversity. We innovate by employing novel view synthesis models to generate augmented training data, significantly enhancing pose estimation in unexplored regions. Moreover, we enhance localization accuracy by integrating pose estimator outputs with sensor data via an extended Kalman filter, demonstrating improved trajectory smoothness and accuracy.},
 author = {Peng, Luyuan and Vishnu, Hari and Chitre, Mandar and Too, Yuen Min and Kalyan, Bharath and Mishra, Rajat and Tan, Soo Pieng},
 date = {2024-07-23},
 eprint = {2407.16961 [cs, eess]},
 eprinttype = {arxiv},
 file = {arXiv Fulltext PDF:/Users/luyuan/Zotero/storage/TW47GLAQ/Peng et al. - 2024 - Pose Estimation from Camera Images for Underwater .pdf:application/pdf;arXiv.org Snapshot:/Users/luyuan/Zotero/storage/TBCP9CKC/2407.html:text/html},
 keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics, Electrical Engineering and Systems Science - Image and Video Processing},
 number = {arXiv:2407.16961},
 publisher = {arXiv},
 title = {Pose Estimation from Camera Images for Underwater Inspection},
 url = {http://arxiv.org/abs/2407.16961},
 urldate = {2024-10-27}
}
